# 基础

这个页面下载spark,最新的是 spark-2.2.0-bin-hadoop2.7.tgz.

<http://spark.apache.org/downloads.html>

这个页面有命令启动独立部署的spark和验证环境是否初始化好了

<http://spark.apache.org/docs/latest/>

这个页面是基于scala的快速入门,介绍了spark的基本概念.末尾介绍了如何在spark上运行自己的项目.

<http://spark.apache.org/docs/latest/quick-start.html>

这个页面告诉了你如何订阅邮件队列.

<http://spark.apache.org/community.html>

这个页面在详细介绍RDD,每个RDD对象有两类方法,Transformations和Actions.这两类方法很重要.

<http://spark.apache.org/docs/latest/rdd-programming-guide.html>

在spark上执行自己的应用

<http://spark.apache.org/docs/latest/submitting-applications.html>

这是spark SQL介绍,不仅能读数据库,还能读Hive

<http://spark.apache.org/docs/latest/sql-programming-guide.html>

hive网址

<https://hive.apache.org/>

程序运行需要创建SparkContext,创建SparkContext 需要SparkConf,创建SparkConf可能需要修改默认配置,这个页面介绍有哪些配置及默认值.

 <http://spark.apache.org/docs/latest/configuration.html>

安全相关的介绍,主要还是说怎么开端口

<http://spark.apache.org/docs/latest/security.html#configuring-ports-for-network-security>

---

# 提高

Spark Streaming

<http://spark.apache.org/docs/latest/streaming-programming-guide.html>

Machine Learning Library (MLlib) 

<http://spark.apache.org/docs/latest/ml-guide.html>

GraphX Programming 

<http://spark.apache.org/docs/latest/graphx-programming-guide.html>



---

# 集群

这个页面概述了spark集群

<http://spark.apache.org/docs/latest/cluster-overview.html>

这个页面说了如何简单的搭建spark集群

<http://spark.apache.org/docs/latest/spark-standalone.html>

这个页面说了如何集成YARN,用YARN来搭建spark集群

<http://spark.apache.org/docs/latest/running-on-yarn.html>

YARN网址

<https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html>

---

# docker

docker pull mesosphere/spark:2.0.1-2.2.0-1-hadoop-2.7




